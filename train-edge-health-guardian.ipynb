{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f384dd19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T08:43:52.007732Z",
     "iopub.status.busy": "2025-11-26T08:43:52.007512Z",
     "iopub.status.idle": "2025-11-26T08:45:04.606390Z",
     "shell.execute_reply": "2025-11-26T08:45:04.605460Z"
    },
    "papermill": {
     "duration": 72.605837,
     "end_time": "2025-11-26T08:45:04.607782",
     "exception": false,
     "start_time": "2025-11-26T08:43:52.001945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 08:43:55.209885: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764146635.396108      21 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764146635.446135      21 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Downloading FER2013 dataset...\n",
      "âœ… Dataset downloaded to: /kaggle/input/fer2013\n",
      "ðŸš€ Loading FER2013 with health labels...\n",
      "âœ… Loaded FER2013: 35887 samples\n",
      "ðŸ“‹ Columns: ['emotion', 'pixels', 'Usage']\n",
      "ðŸ”¢ Emotion value counts:\n",
      "emotion\n",
      "0    4953\n",
      "1     547\n",
      "2    5121\n",
      "3    8989\n",
      "4    6077\n",
      "5    4002\n",
      "6    6198\n",
      "Name: count, dtype: int64\n",
      "ðŸ–¼ï¸ Processing images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764146654.991660      21 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Processed 5000/35887 images...\n",
      "   Processed 10000/35887 images...\n",
      "   Processed 15000/35887 images...\n",
      "   Processed 20000/35887 images...\n",
      "   Processed 25000/35887 images...\n",
      "   Processed 30000/35887 images...\n",
      "   Processed 35000/35887 images...\n",
      "ðŸ“Š Final Dataset:\n",
      "   Images shape: (35887, 96, 96, 3)\n",
      "   Stress: 46.5% positive\n",
      "   Fatigue: 34.2% positive\n",
      "   Anomaly: 1.5% positive\n",
      "\n",
      "ðŸŽ¯ Dataset ready for training!\n",
      "   X shape: (35887, 96, 96, 3)\n",
      "   y keys: ['stress', 'fatigue', 'anomaly']\n",
      "\n",
      "ðŸ“Š Training set: 28709 samples\n",
      "ðŸ“Š Validation set: 7178 samples\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "# Download latest version\n",
    "print(\"ðŸ“¥ Downloading FER2013 dataset...\")\n",
    "path = kagglehub.dataset_download(\"deadskull7/fer2013\")\n",
    "print(f\"âœ… Dataset downloaded to: {path}\")\n",
    "\n",
    "def load_fer2013_with_health_labels():\n",
    "    \"\"\"Load FER2013 and convert to CLEAR stress/fatigue/anomaly labels\"\"\"\n",
    "    \n",
    "    # Find the CSV file in the downloaded path\n",
    "    fer_csv_path = Path(path) / \"fer2013.csv\"\n",
    "    \n",
    "    if not fer_csv_path.exists():\n",
    "        # Try alternative paths\n",
    "        possible_files = list(Path(path).rglob(\"*.csv\"))\n",
    "        if possible_files:\n",
    "            fer_csv_path = possible_files[0]\n",
    "            print(f\"ðŸ“ Found CSV at: {fer_csv_path}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"CSV file not found in {path}\")\n",
    "    \n",
    "    fer_df = pd.read_csv(fer_csv_path)\n",
    "    print(f\"âœ… Loaded FER2013: {len(fer_df)} samples\")\n",
    "    \n",
    "    # Check the structure of the dataset\n",
    "    print(f\"ðŸ“‹ Columns: {fer_df.columns.tolist()}\")\n",
    "    if 'emotion' not in fer_df.columns:\n",
    "        print(\"âŒ 'emotion' column not found. Available columns:\", fer_df.columns.tolist())\n",
    "        # Try to find emotion column with different name\n",
    "        if 'label' in fer_df.columns:\n",
    "            fer_df = fer_df.rename(columns={'label': 'emotion'})\n",
    "            print(\"âœ… Renamed 'label' column to 'emotion'\")\n",
    "        else:\n",
    "            raise KeyError(\"Could not find emotion/label column in dataset\")\n",
    "    \n",
    "    print(f\"ðŸ”¢ Emotion value counts:\\n{fer_df['emotion'].value_counts().sort_index()}\")\n",
    "    \n",
    "    # Convert emotion labels to CLEAR binary health labels\n",
    "    emotion_labels = fer_df['emotion'].values\n",
    "    \n",
    "    stress_labels = []\n",
    "    fatigue_labels = [] \n",
    "    anomaly_labels = []\n",
    "    \n",
    "    # Emotion mapping for FER2013:\n",
    "    # 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
    "    \n",
    "    for emotion in emotion_labels:\n",
    "        # STRESS: Clear binary - negative emotions = stress\n",
    "        if emotion in [0, 1, 2, 4]:  # Angry, Disgust, Fear, Sad\n",
    "            stress = 1.0\n",
    "        else:\n",
    "            stress = 0.0\n",
    "            \n",
    "        # FATIGUE: Clear binary - tired-looking expressions\n",
    "        if emotion in [4, 6]:  # Sad, Neutral\n",
    "            fatigue = 1.0\n",
    "        else:\n",
    "            fatigue = 0.0\n",
    "            \n",
    "        # ANOMALY: Clear binary - rare emotion (Disgust)\n",
    "        if emotion == 1:  # Disgust (rarest in dataset)\n",
    "            anomaly = 1.0\n",
    "        else:\n",
    "            anomaly = 0.0\n",
    "            \n",
    "        stress_labels.append(stress)\n",
    "        fatigue_labels.append(fatigue)\n",
    "        anomaly_labels.append(anomaly)\n",
    "    \n",
    "    health_labels = {\n",
    "        'stress': np.array(stress_labels, dtype=np.float32),\n",
    "        'fatigue': np.array(fatigue_labels, dtype=np.float32),\n",
    "        'anomaly': np.array(anomaly_labels, dtype=np.float32)\n",
    "    }\n",
    "    \n",
    "    # Process images (resize to 96x96, 3 channels)\n",
    "    print(\"ðŸ–¼ï¸ Processing images...\")\n",
    "    images = []\n",
    "    \n",
    "    # Check if we have pixels column\n",
    "    if 'pixels' not in fer_df.columns:\n",
    "        # Try to find image data in other columns\n",
    "        image_columns = [col for col in fer_df.columns if 'pixel' in col.lower() or 'image' in col.lower()]\n",
    "        if image_columns:\n",
    "            pixel_col = image_columns[0]\n",
    "            print(f\"âœ… Using column '{pixel_col}' for image data\")\n",
    "        else:\n",
    "            raise KeyError(\"Could not find pixel data column\")\n",
    "    else:\n",
    "        pixel_col = 'pixels'\n",
    "    \n",
    "    for i, pixel_str in enumerate(fer_df[pixel_col]):\n",
    "        # Handle different data formats\n",
    "        if isinstance(pixel_str, str):\n",
    "            pixels = np.array(pixel_str.split(), dtype=np.float32)\n",
    "        else:\n",
    "            pixels = pixel_str.astype(np.float32)\n",
    "        \n",
    "        # Reshape to 48x48 (FER2013 standard size)\n",
    "        try:\n",
    "            pixels = pixels.reshape(48, 48)\n",
    "        except:\n",
    "            # Try other common dimensions\n",
    "            for size in [48, 64, 96]:\n",
    "                try:\n",
    "                    pixels = pixels.reshape(size, size)\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        # Convert to 3 channels and resize to 96x96\n",
    "        img = np.stack([pixels] * 3, axis=-1)\n",
    "        img = tf.image.resize(img, [96, 96]).numpy()\n",
    "        images.append(img)\n",
    "        \n",
    "        # Progress indicator\n",
    "        if i % 5000 == 0 and i > 0:\n",
    "            print(f\"   Processed {i}/{len(fer_df)} images...\")\n",
    "    \n",
    "    images = np.array(images) / 255.0  # Normalize to [0,1]\n",
    "    \n",
    "    print(f\"ðŸ“Š Final Dataset:\")\n",
    "    print(f\"   Images shape: {images.shape}\")\n",
    "    print(f\"   Stress: {np.mean(health_labels['stress']):.1%} positive\")\n",
    "    print(f\"   Fatigue: {np.mean(health_labels['fatigue']):.1%} positive\") \n",
    "    print(f\"   Anomaly: {np.mean(health_labels['anomaly']):.1%} positive\")\n",
    "    \n",
    "    return images, health_labels\n",
    "\n",
    "# Usage in your training:\n",
    "print(\"ðŸš€ Loading FER2013 with health labels...\")\n",
    "X, y = load_fer2013_with_health_labels()\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Dataset ready for training!\")\n",
    "print(f\"   X shape: {X.shape}\")\n",
    "print(f\"   y keys: {list(y.keys())}\")\n",
    "\n",
    "# Split into train/validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For multi-output, we need to split indices\n",
    "indices = np.arange(len(X))\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42, stratify=y['stress'])\n",
    "\n",
    "X_train, X_val = X[train_idx], X[val_idx]\n",
    "y_train = {k: v[train_idx] for k, v in y.items()}\n",
    "y_val = {k: v[val_idx] for k, v in y.items()}\n",
    "\n",
    "print(f\"\\nðŸ“Š Training set: {len(X_train)} samples\")\n",
    "print(f\"ðŸ“Š Validation set: {len(X_val)} samples\")\n",
    "\n",
    "# Now train your model - it will actually learn!\n",
    "# model.train(X_train, y_train, X_val, y_val, use_class_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2243cf7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T08:45:04.617620Z",
     "iopub.status.busy": "2025-11-26T08:45:04.617387Z",
     "iopub.status.idle": "2025-11-26T08:45:04.620803Z",
     "shell.execute_reply": "2025-11-26T08:45:04.620277Z"
    },
    "papermill": {
     "duration": 0.009245,
     "end_time": "2025-11-26T08:45:04.621708",
     "exception": false,
     "start_time": "2025-11-26T08:45:04.612463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('/kaggle/working/src', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381cff56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T08:45:04.635600Z",
     "iopub.status.busy": "2025-11-26T08:45:04.635403Z",
     "iopub.status.idle": "2025-11-26T08:45:04.645036Z",
     "shell.execute_reply": "2025-11-26T08:45:04.644397Z"
    },
    "papermill": {
     "duration": 0.020039,
     "end_time": "2025-11-26T08:45:04.645988",
     "exception": false,
     "start_time": "2025-11-26T08:45:04.625949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/src/train_face_model_kaggle.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/src/train_face_model_kaggle.py\n",
    "# src/train_face_model_kaggle.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('/kaggle/working/src')\n",
    "\n",
    "from stress_model import StressDetectionModel, make_representative_gen_from_numpy\n",
    "\n",
    "print(\"âœ… TensorFlow version:\", tf.__version__)\n",
    "print(\"âœ… GPU available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "class FaceModelTrainerKaggle:\n",
    "    def __init__(self, input_shape=(96, 96, 3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = None\n",
    "        self.setup_logging()\n",
    "        \n",
    "    def setup_logging(self):\n",
    "        \"\"\"Setup logging for Kaggle\"\"\"\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger('FaceModelTrainer')\n",
    "    \n",
    "    def load_fer2013_data(self):\n",
    "        \"\"\"Load FER2013 dataset from Kaggle input\"\"\"\n",
    "        self.logger.info(\"ðŸ“¥ Loading FER2013 dataset from Kaggle...\")\n",
    "        \n",
    "        try:\n",
    "            # Kaggle dataset path\n",
    "            fer_csv = Path(\"/kaggle/input/fer2013/fer2013.csv\")\n",
    "            fer_df = pd.read_csv(fer_csv)\n",
    "            self.logger.info(f\"ðŸ“Š Total samples: {len(fer_df):,}\")\n",
    "            \n",
    "            # Preprocess images\n",
    "            X, y = [], []\n",
    "            \n",
    "            for idx, row in fer_df.iterrows():\n",
    "                if idx % 5000 == 0:\n",
    "                    self.logger.info(f\"  Processed {idx}/{len(fer_df)} images...\")\n",
    "                \n",
    "                # Convert pixel string to array\n",
    "                pixels = np.array(row['pixels'].split(), dtype='float32').reshape(48, 48)\n",
    "                pixels = np.stack([pixels]*3, axis=-1)  # 3 channels\n",
    "                pixels /= 255.0  # Normalize\n",
    "                X.append(pixels)\n",
    "                y.append(row['emotion'])\n",
    "            \n",
    "            X = np.array(X)\n",
    "            \n",
    "            # Convert to categorical (7 emotions)\n",
    "            from tensorflow.keras.utils import to_categorical\n",
    "            y = to_categorical(y, num_classes=7)\n",
    "            \n",
    "            # Resize to target shape\n",
    "            X_resized = np.array([tf.image.resize(img, self.input_shape[:2]).numpy() for img in X])\n",
    "            \n",
    "            # Convert emotions to stress/fatigue labels - FIXED CLEAR BINARY LABELS\n",
    "            stress_labels, fatigue_labels, anomaly_labels = self._emotion_to_health_labels(y)\n",
    "            \n",
    "            labels = {\n",
    "                'stress': stress_labels,\n",
    "                'fatigue': fatigue_labels,\n",
    "                'anomaly': anomaly_labels\n",
    "            }\n",
    "            \n",
    "            self.logger.info(f\"âœ… Loaded FER2013 data: {X_resized.shape}\")\n",
    "            return X_resized, labels\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"âŒ Error loading data: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _emotion_to_health_labels(self, emotion_labels):\n",
    "        \"\"\"Convert FER2013 emotions to CLEAR BINARY stress/fatigue labels\"\"\"\n",
    "        stress_labels = []\n",
    "        fatigue_labels = []\n",
    "        anomaly_labels = []\n",
    "        \n",
    "        for emotion_vec in emotion_labels:\n",
    "            emotion_idx = np.argmax(emotion_vec)\n",
    "            \n",
    "            # FIXED: CLEAR BINARY LABELS - no overlapping ranges!\n",
    "            # Stress: 1 for negative emotions, 0 otherwise\n",
    "            if emotion_idx in [0, 1, 2, 4]:  # Angry, Disgust, Fear, Sad\n",
    "                stress = 1.0\n",
    "            else:\n",
    "                stress = 0.0\n",
    "            \n",
    "            # Fatigue: 1 for tired-looking expressions, 0 otherwise\n",
    "            if emotion_idx in [4, 6]:  # Sad, Neutral\n",
    "                fatigue = 1.0\n",
    "            else:\n",
    "                fatigue = 0.0\n",
    "            \n",
    "            # Anomaly: 1 for rare emotion (Disgust), 0 otherwise\n",
    "            if emotion_idx == 1:  # Disgust (rarest)\n",
    "                anomaly = 1.0\n",
    "            else:\n",
    "                anomaly = 0.0\n",
    "            \n",
    "            stress_labels.append(stress)\n",
    "            fatigue_labels.append(fatigue)\n",
    "            anomaly_labels.append(anomaly)\n",
    "        \n",
    "        return np.array(stress_labels), np.array(fatigue_labels), np.array(anomaly_labels)\n",
    "    \n",
    "    def calculate_class_weights(self, y_train):\n",
    "        \"\"\"Calculate class weights to handle imbalanced data\"\"\"\n",
    "        self.logger.info(\"âš–ï¸ Calculating class weights...\")\n",
    "        class_weights = {}\n",
    "        \n",
    "        for task in ['stress', 'fatigue', 'anomaly']:\n",
    "            if task in y_train:\n",
    "                # Convert to binary labels for weight calculation\n",
    "                binary_labels = (y_train[task] > 0.5).astype(int)\n",
    "                \n",
    "                try:\n",
    "                    weights = compute_class_weight(\n",
    "                        'balanced', \n",
    "                        classes=np.unique(binary_labels), \n",
    "                        y=binary_labels\n",
    "                    )\n",
    "                    class_weights[task] = {0: float(weights[0]), 1: float(weights[1])}\n",
    "                    self.logger.info(f\"âœ… {task} class weights: {class_weights[task]}\")\n",
    "                except Exception as e:\n",
    "                    self.logger.warning(f\"âš ï¸ Using default weights for {task}: {e}\")\n",
    "                    class_weights[task] = {0: 1.0, 1: 1.0}\n",
    "        \n",
    "        return class_weights\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare training data\"\"\"\n",
    "        X, labels = self.load_fer2013_data()\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "        \n",
    "        y_train = {}\n",
    "        y_test = {}\n",
    "        for key in labels.keys():\n",
    "            y_train[key], y_test[key] = train_test_split(\n",
    "                labels[key], test_size=0.2, random_state=42\n",
    "            )\n",
    "        \n",
    "        self.logger.info(f\"ðŸ“š Training samples: {len(X_train):,}\")\n",
    "        self.logger.info(f\"ðŸ“š Validation samples: {len(X_test):,}\")\n",
    "        \n",
    "        # Log class distribution\n",
    "        self.logger.info(\"ðŸ“Š Class Distribution:\")\n",
    "        for task in ['stress', 'fatigue', 'anomaly']:\n",
    "            pos_rate = np.mean(y_train[task] > 0.5)\n",
    "            self.logger.info(f\"   {task}: {pos_rate:.1%} positive\")\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def train_model(self, epochs=50, batch_size=32, use_class_weights=True):\n",
    "        \"\"\"Train the model on Kaggle GPU with class weights\"\"\"\n",
    "        self.logger.info(\"ðŸ‹ï¸ Starting training on Kaggle GPU...\")\n",
    "        \n",
    "        # Prepare data\n",
    "        X_train, X_test, y_train, y_test = self.prepare_data()\n",
    "        \n",
    "        # Calculate class weights\n",
    "        class_weights = None\n",
    "        if use_class_weights:\n",
    "            class_weights = self.calculate_class_weights(y_train)\n",
    "        \n",
    "        # Build model\n",
    "        self.model = StressDetectionModel(self.input_shape)\n",
    "        self.model.build_temporal_attention_model()\n",
    "        \n",
    "        # Compile with improved metrics for imbalanced data\n",
    "        self.model.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "            loss={\n",
    "                'stress': 'binary_crossentropy',\n",
    "                'fatigue': 'binary_crossentropy',\n",
    "                'anomaly': 'binary_crossentropy'\n",
    "            },\n",
    "            metrics={\n",
    "                'stress': [\n",
    "                    tf.keras.metrics.Precision(name='precision'),\n",
    "                    tf.keras.metrics.Recall(name='recall'),\n",
    "                    tf.keras.metrics.AUC(name='auc'),  # Better for imbalanced data\n",
    "                    tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "                ],\n",
    "                'fatigue': [\n",
    "                    tf.keras.metrics.Precision(name='precision'),\n",
    "                    tf.keras.metrics.Recall(name='recall'),\n",
    "                    tf.keras.metrics.AUC(name='auc'),\n",
    "                    tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "                ],\n",
    "                'anomaly': [\n",
    "                    tf.keras.metrics.Precision(name='precision'),\n",
    "                    tf.keras.metrics.Recall(name='recall'),\n",
    "                    tf.keras.metrics.AUC(name='auc'),\n",
    "                    tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Kaggle-optimized callbacks\n",
    "        callbacks_list = [\n",
    "            callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=10,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-7\n",
    "            ),\n",
    "            callbacks.ModelCheckpoint(\n",
    "                '/kaggle/working/face_analyzer_best.h5',\n",
    "                monitor='val_stress_auc',  # Monitor AUC instead of loss\n",
    "                save_best_only=True,\n",
    "                mode='max'\n",
    "            ),\n",
    "            callbacks.CSVLogger('/kaggle/working/training_log.csv')\n",
    "        ]\n",
    "        \n",
    "        # Train with GPU and class weights\n",
    "        self.logger.info(\"ðŸš€ Training started...\")\n",
    "        if class_weights:\n",
    "            self.logger.info(f\"ðŸŽ¯ Using class weights: {class_weights}\")\n",
    "        \n",
    "        history = self.model.model.fit(\n",
    "            X_train,\n",
    "            {\n",
    "                'stress': y_train['stress'],\n",
    "                'fatigue': y_train['fatigue'],\n",
    "                'anomaly': y_train['anomaly']\n",
    "            },\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(\n",
    "                X_test,\n",
    "                {\n",
    "                    'stress': y_test['stress'],\n",
    "                    'fatigue': y_test['fatigue'],\n",
    "                    'anomaly': y_test['anomaly']\n",
    "                }\n",
    "            ),\n",
    "            callbacks=callbacks_list,\n",
    "            class_weight=class_weights,  # ADDED CLASS WEIGHTS\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Save final model\n",
    "        self.model.model.save('/kaggle/working/face_analyzer.h5')\n",
    "        \n",
    "        # Save history\n",
    "        with open('/kaggle/working/training_history.json', 'w') as f:\n",
    "            json.dump({k: [float(x) for x in v] for k, v in history.history.items()}, f)\n",
    "        \n",
    "        # Enhanced evaluation\n",
    "        self.enhanced_evaluation(X_test, y_test)\n",
    "        \n",
    "        self.logger.info(\"âœ… Training complete!\")\n",
    "        return history\n",
    "    \n",
    "    def enhanced_evaluation(self, X_test, y_test):\n",
    "        \"\"\"Enhanced evaluation with detailed metrics\"\"\"\n",
    "        self.logger.info(\"ðŸ“Š Running enhanced evaluation...\")\n",
    "        \n",
    "        predictions = self.model.model.predict(X_test, verbose=0)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ðŸŽ¯ ENHANCED MODEL EVALUATION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for i, task in enumerate(['stress', 'fatigue', 'anomaly']):\n",
    "            if task in y_test:\n",
    "                true_probs = y_test[task]\n",
    "                pred_probs = predictions[i].flatten()\n",
    "                true_binary = (true_probs > 0.5).astype(int)\n",
    "                \n",
    "                from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
    "                \n",
    "                # Calculate AUC\n",
    "                try:\n",
    "                    auc = roc_auc_score(true_binary, pred_probs)\n",
    "                except:\n",
    "                    auc = 0.0\n",
    "                \n",
    "                # Find optimal threshold\n",
    "                best_f1 = 0\n",
    "                best_threshold = 0.5\n",
    "                \n",
    "                for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "                    pred_binary = (pred_probs > threshold).astype(int)\n",
    "                    f1 = f1_score(true_binary, pred_binary, zero_division=0)\n",
    "                    if f1 > best_f1:\n",
    "                        best_f1 = f1\n",
    "                        best_threshold = threshold\n",
    "                \n",
    "                print(f\"\\n{task.upper()}:\")\n",
    "                print(f\"  AUC: {auc:.4f}\")\n",
    "                print(f\"  Best F1: {best_f1:.4f} (threshold: {best_threshold:.2f})\")\n",
    "                print(f\"  Positive Rate: {np.mean(true_binary):.1%}\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    def convert_to_tflite(self):\n",
    "        \"\"\"Convert to TFLite for edge deployment\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Train model first!\")\n",
    "        \n",
    "        self.logger.info(\"ðŸ”„ Converting to TFLite...\")\n",
    "        \n",
    "        # Load some data for quantization\n",
    "        X_train, _, _, _ = self.prepare_data()\n",
    "        representative_gen = make_representative_gen_from_numpy(X_train[:100])\n",
    "        \n",
    "        # Convert\n",
    "        self.model.save_as_tflite(\n",
    "            filepath='/kaggle/working/face_analyzer_int8.tflite',\n",
    "            representative_gen=representative_gen,\n",
    "            full_integer=True\n",
    "        )\n",
    "        \n",
    "        self.logger.info(\"âœ… TFLite model saved!\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main training function for Kaggle\"\"\"\n",
    "    print(\"ðŸš€ Starting Edge Health Guardian Training on Kaggle\")\n",
    "    print(\"==================================================\")\n",
    "    \n",
    "    # Create output directory\n",
    "    Path('/kaggle/working').mkdir(exist_ok=True)\n",
    "    \n",
    "    # Initialize and train\n",
    "    trainer = FaceModelTrainerKaggle(input_shape=(96, 96, 3))\n",
    "    \n",
    "    try:\n",
    "        # Train model WITH CLASS WEIGHTS\n",
    "        history = trainer.train_model(\n",
    "            epochs=30,\n",
    "            batch_size=64,\n",
    "            use_class_weights=True  # ENABLE CLASS WEIGHTS\n",
    "        )\n",
    "        \n",
    "        # Convert to TFLite\n",
    "        trainer.convert_to_tflite()\n",
    "        \n",
    "        # List output files\n",
    "        print(\"\\nðŸ“ Output files created:\")\n",
    "        for file in Path('/kaggle/working').glob('*'):\n",
    "            if file.is_file():\n",
    "                size_mb = file.stat().st_size / (1024 * 1024)\n",
    "                print(f\"  {file.name} ({size_mb:.1f} MB)\")\n",
    "        \n",
    "        print(\"\\nðŸŽ‰ Training completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Training failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de7bcb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T08:45:04.655850Z",
     "iopub.status.busy": "2025-11-26T08:45:04.655660Z",
     "iopub.status.idle": "2025-11-26T08:45:04.664900Z",
     "shell.execute_reply": "2025-11-26T08:45:04.664145Z"
    },
    "papermill": {
     "duration": 0.015679,
     "end_time": "2025-11-26T08:45:04.665920",
     "exception": false,
     "start_time": "2025-11-26T08:45:04.650241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/src/stress_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/src/stress_model.py\n",
    "# stress_model.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from typing import Generator, Dict, List, Union\n",
    "from pathlib import Path\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class StressDetectionModel:\n",
    "    def __init__(self, input_shape: tuple):\n",
    "        self.input_shape = input_shape\n",
    "        self.model: tf.keras.Model = None\n",
    "        self.class_weights: Dict = None\n",
    "\n",
    "    def build_temporal_attention_model(self) -> tf.keras.Model:\n",
    "        \"\"\"Build CNN + LSTM + temporal attention for stress, fatigue, anomaly detection\"\"\"\n",
    "        inputs = tf.keras.Input(shape=self.input_shape)\n",
    "\n",
    "        # Spatial feature extraction (CNN)\n",
    "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "        # Feature transformation\n",
    "        x = layers.Dense(256, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        \n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "\n",
    "        # Multi-output for stress, fatigue, anomaly\n",
    "        stress_output = layers.Dense(1, activation='sigmoid', name='stress')(x)\n",
    "        fatigue_output = layers.Dense(1, activation='sigmoid', name='fatigue')(x)\n",
    "        anomaly_output = layers.Dense(1, activation='sigmoid', name='anomaly')(x)\n",
    "\n",
    "        self.model = models.Model(inputs=inputs, outputs=[stress_output, fatigue_output, anomaly_output])\n",
    "        return self.model\n",
    "\n",
    "    def build_temporal_attention_model_complex(self) -> tf.keras.Model:\n",
    "        \"\"\"Alternative: Use TFLite-compatible LSTM without CuDNN\"\"\"\n",
    "        inputs = tf.keras.Input(shape=self.input_shape)\n",
    "\n",
    "        # Spatial feature extraction (CNN)\n",
    "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "        # Create sequence by repeating features (simulate temporal dimension)\n",
    "        x = layers.RepeatVector(1)(x)  # Single timestep sequence\n",
    "        \n",
    "        # Use TFLite-compatible LSTM (disable CuDNN)\n",
    "        x = layers.LSTM(64, return_sequences=True, implementation=2)(x)  # implementation=2 avoids CuDNN\n",
    "        \n",
    "        # Simple attention mechanism (avoid complex operations that break TFLite)\n",
    "        attention = layers.Dense(1, activation='tanh')(x)\n",
    "        attention = layers.Flatten()(attention)\n",
    "        attention = layers.Activation('softmax')(attention)\n",
    "        \n",
    "        # Apply attention\n",
    "        x = layers.Flatten()(x)\n",
    "        attended_features = layers.Dot(axes=1)([x, attention])\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = layers.Dense(128, activation='relu')(attended_features)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "\n",
    "        # Multi-output for stress, fatigue, anomaly\n",
    "        stress_output = layers.Dense(1, activation='sigmoid', name='stress')(x)\n",
    "        fatigue_output = layers.Dense(1, activation='sigmoid', name='fatigue')(x)\n",
    "        anomaly_output = layers.Dense(1, activation='sigmoid', name='anomaly')(x)\n",
    "\n",
    "        self.model = models.Model(inputs=inputs, outputs=[stress_output, fatigue_output, anomaly_output])\n",
    "        return self.model\n",
    "\n",
    "    def calculate_class_weights(self, train_labels: Dict[str, np.ndarray]):\n",
    "        \"\"\"Calculate class weights to handle imbalanced data\"\"\"\n",
    "        self.class_weights = {}\n",
    "        \n",
    "        for task in ['stress', 'fatigue', 'anomaly']:\n",
    "            if task in train_labels:\n",
    "                labels = train_labels[task]\n",
    "                # Convert continuous labels to binary for weight calculation\n",
    "                binary_labels = (labels > 0.5).astype(int)\n",
    "                \n",
    "                try:\n",
    "                    class_weights = compute_class_weight(\n",
    "                        'balanced', \n",
    "                        classes=np.unique(binary_labels), \n",
    "                        y=binary_labels\n",
    "                    )\n",
    "                    self.class_weights[task] = {\n",
    "                        0: float(class_weights[0]), \n",
    "                        1: float(class_weights[1])\n",
    "                    }\n",
    "                    print(f\"âœ… {task} class weights: {self.class_weights[task]}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ Could not calculate weights for {task}: {e}\")\n",
    "                    self.class_weights[task] = {0: 1.0, 1: 1.0}\n",
    "\n",
    "    def compile_model(self, lr: float = 1e-3, use_improved_metrics: bool = True):\n",
    "        \"\"\"Compile model with improved metrics for imbalanced data\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Build the model first (call build_temporal_attention_model).\")\n",
    "\n",
    "        if use_improved_metrics:\n",
    "            # Use metrics that work better with imbalanced data\n",
    "            metrics_config = {\n",
    "                'stress': [\n",
    "                    tf.keras.metrics.Precision(name='precision'),\n",
    "                    tf.keras.metrics.Recall(name='recall'),\n",
    "                    tf.keras.metrics.AUC(name='auc'),  # Better for imbalanced data\n",
    "                    tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "                ],\n",
    "                'fatigue': [\n",
    "                    tf.keras.metrics.Precision(name='precision'),\n",
    "                    tf.keras.metrics.Recall(name='recall'), \n",
    "                    tf.keras.metrics.AUC(name='auc'),\n",
    "                    tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "                ],\n",
    "                'anomaly': [\n",
    "                    tf.keras.metrics.Precision(name='precision'),\n",
    "                    tf.keras.metrics.Recall(name='recall'),\n",
    "                    tf.keras.metrics.AUC(name='auc'),\n",
    "                    tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "                ]\n",
    "            }\n",
    "        else:\n",
    "            # Original metrics\n",
    "            metrics_config = {\n",
    "                'stress': [\n",
    "                    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                    tf.keras.metrics.Precision(name='precision'),\n",
    "                    tf.keras.metrics.Recall(name='recall')\n",
    "                ],\n",
    "                'fatigue': [\n",
    "                    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                    tf.keras.metrics.Precision(name='precision'),\n",
    "                    tf.keras.metrics.Recall(name='recall')\n",
    "                ],\n",
    "                'anomaly': [\n",
    "                    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                    tf.keras.metrics.Precision(name='precision'),\n",
    "                    tf.keras.metrics.Recall(name='recall')\n",
    "                ]\n",
    "            }\n",
    "\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "            loss={\n",
    "                'stress': 'binary_crossentropy',\n",
    "                'fatigue': 'binary_crossentropy',\n",
    "                'anomaly': 'binary_crossentropy'\n",
    "            },\n",
    "            metrics=metrics_config\n",
    "        )\n",
    "\n",
    "    def quantize_model(self):\n",
    "        \"\"\"Apply quantization-aware training (QAT)\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Build the model first (call build_temporal_attention_model).\")\n",
    "        quantize_model_fn = tfmot.quantization.keras.quantize_model\n",
    "        self.model = quantize_model_fn(self.model)\n",
    "        self.compile_model()\n",
    "\n",
    "    def train(self,\n",
    "              train_input,\n",
    "              train_labels,\n",
    "              val_input,\n",
    "              val_labels,\n",
    "              epochs: int = 10,\n",
    "              batch_size: int = 32,\n",
    "              callbacks_list = None,\n",
    "              use_class_weights: bool = True,\n",
    "              verbose: int = 1):\n",
    "        \"\"\"Train the model with optional class weighting\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Build and compile the model before training.\")\n",
    "        \n",
    "        # Calculate class weights if requested\n",
    "        if use_class_weights and self.class_weights is None:\n",
    "            self.calculate_class_weights(train_labels)\n",
    "        \n",
    "        # Prepare class weights for training\n",
    "        class_weight_dict = None\n",
    "        if use_class_weights and self.class_weights:\n",
    "            class_weight_dict = self.class_weights\n",
    "            print(\"ðŸŽ¯ Using class weights for training:\", class_weight_dict)\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            train_input,\n",
    "            train_labels,\n",
    "            validation_data=(val_input, val_labels),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks_list,\n",
    "            class_weight=class_weight_dict,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def evaluate_model(self, test_input, test_labels, threshold: float = 0.5):\n",
    "        \"\"\"Enhanced evaluation with custom threshold support\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model must be trained before evaluation.\")\n",
    "        \n",
    "        # Standard evaluation\n",
    "        standard_results = self.model.evaluate(test_input, test_labels, verbose=0)\n",
    "        \n",
    "        # Custom evaluation with adjustable threshold\n",
    "        predictions = self.model.predict(test_input, verbose=0)\n",
    "        \n",
    "        print(\"\\nðŸ“Š ENHANCED MODEL EVALUATION:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for i, task in enumerate(['stress', 'fatigue', 'anomaly']):\n",
    "            if task in test_labels:\n",
    "                true_labels = test_labels[task]\n",
    "                pred_probs = predictions[i].flatten()\n",
    "                pred_labels = (pred_probs > threshold).astype(int)\n",
    "                true_binary = (true_labels > 0.5).astype(int)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
    "                \n",
    "                f1 = f1_score(true_binary, pred_labels, zero_division=0)\n",
    "                try:\n",
    "                    auc = roc_auc_score(true_binary, pred_probs)\n",
    "                except:\n",
    "                    auc = 0.0\n",
    "                \n",
    "                print(f\"\\n{task.upper()} (threshold={threshold}):\")\n",
    "                print(f\"  F1-Score: {f1:.4f}\")\n",
    "                print(f\"  AUC: {auc:.4f}\")\n",
    "                print(f\"  Positive Rate: {np.mean(pred_labels):.4f}\")\n",
    "                print(classification_report(true_binary, pred_labels, \n",
    "                                          target_names=['Negative', 'Positive'], \n",
    "                                          zero_division=0))\n",
    "        \n",
    "        return standard_results\n",
    "\n",
    "    def save_as_tflite(self,\n",
    "                       filepath: str,\n",
    "                       representative_gen: Generator = None,\n",
    "                       full_integer: bool = True):\n",
    "        \"\"\"Convert model to TFLite (optionally INT8 quantized)\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model must be built/loaded before saving to TFLite.\")\n",
    "\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(self.model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "        if representative_gen is not None and full_integer:\n",
    "            converter.representative_dataset = representative_gen\n",
    "            converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "            converter.inference_input_type = tf.int8\n",
    "            converter.inference_output_type = tf.int8\n",
    "\n",
    "        tflite_model = converter.convert()\n",
    "        Path(filepath).parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print(f\"âœ… TFLite model saved to: {filepath}\")\n",
    "\n",
    "    def find_optimal_threshold(self, val_input, val_labels, task: str = 'stress'):\n",
    "        \"\"\"Find optimal classification threshold using validation data\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model must be trained before threshold optimization.\")\n",
    "        \n",
    "        predictions = self.model.predict(val_input, verbose=0)\n",
    "        task_idx = ['stress', 'fatigue', 'anomaly'].index(task)\n",
    "        pred_probs = predictions[task_idx].flatten()\n",
    "        true_labels = (val_labels[task] > 0.5).astype(int)\n",
    "        \n",
    "        # Find optimal threshold using F1-score\n",
    "        from sklearn.metrics import f1_score\n",
    "        best_threshold = 0.5\n",
    "        best_f1 = 0\n",
    "        \n",
    "        for threshold in np.arange(0.1, 0.9, 0.05):\n",
    "            pred_labels = (pred_probs > threshold).astype(int)\n",
    "            f1 = f1_score(true_labels, pred_labels, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        print(f\"ðŸŽ¯ Optimal threshold for {task}: {best_threshold:.3f} (F1: {best_f1:.3f})\")\n",
    "        return best_threshold\n",
    "\n",
    "# Representative generator helper\n",
    "def make_representative_gen_from_numpy(x_samples: np.ndarray, num_steps: int = 100):\n",
    "    \"\"\"Yield representative samples for TFLite INT8 quantization\"\"\"\n",
    "    def rep_gen():\n",
    "        count = 0\n",
    "        for i in range(min(num_steps, len(x_samples))):\n",
    "            yield [x_samples[i:i+1].astype(np.float32)]\n",
    "            count += 1\n",
    "            if count >= num_steps:\n",
    "                break\n",
    "    return rep_gen\n",
    "\n",
    "# Enhanced training callback for imbalanced data\n",
    "class ImbalancedDataCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data, task_names=['stress', 'fatigue', 'anomaly']):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.task_names = task_names\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 5 == 0:  # Print every 5 epochs\n",
    "            print(f\"\\nðŸ“ˆ Epoch {epoch} - Class Distribution Insights:\")\n",
    "            for task in self.task_names:\n",
    "                if task in self.validation_data[1]:\n",
    "                    labels = self.validation_data[1][task]\n",
    "                    positive_ratio = np.mean(labels > 0.5)\n",
    "                    print(f\"  {task}: {positive_ratio:.1%} positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4093dd3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T08:45:04.675805Z",
     "iopub.status.busy": "2025-11-26T08:45:04.675591Z",
     "iopub.status.idle": "2025-11-26T08:45:04.684011Z",
     "shell.execute_reply": "2025-11-26T08:45:04.683329Z"
    },
    "papermill": {
     "duration": 0.01495,
     "end_time": "2025-11-26T08:45:04.685235",
     "exception": false,
     "start_time": "2025-11-26T08:45:04.670285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/src/train_movement_model_kaggle.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/src/train_movement_model_kaggle.py\n",
    "# train_movement_model_kaggle.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"âœ… Movement model Kaggle script loaded\")\n",
    "\n",
    "class MovementModelTrainerKaggle:\n",
    "    def __init__(self, sequence_length=50, feature_dim=12):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.feature_dim = feature_dim\n",
    "        self.model = None\n",
    "        self.setup_logging()\n",
    "    \n",
    "    def setup_logging(self):\n",
    "        \"\"\"Setup logging for Kaggle\"\"\"\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger('MovementModelTrainer')\n",
    "    \n",
    "    def generate_realistic_movement_data(self, num_samples=15000):\n",
    "        \"\"\"Generate realistic movement data simulating accelerometer and gyroscope patterns\"\"\"\n",
    "        self.logger.info(\"ðŸ“Š Generating realistic movement data...\")\n",
    "        \n",
    "        X = []\n",
    "        stress_labels = []\n",
    "        fatigue_labels = []\n",
    "        anomaly_labels = []\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            # Generate time series data\n",
    "            time_steps = np.linspace(0, 5, self.sequence_length)\n",
    "            \n",
    "            # Base patterns\n",
    "            if i < num_samples * 0.7:  # 70% normal movement\n",
    "                # Smooth, coordinated movements\n",
    "                accel_x = 0.5 * np.sin(2 * np.pi * 1 * time_steps) + 0.1 * np.random.normal(size=self.sequence_length)\n",
    "                accel_y = 0.5 * np.cos(2 * np.pi * 1 * time_steps) + 0.1 * np.random.normal(size=self.sequence_length)\n",
    "                accel_z = 9.8 + 0.05 * np.random.normal(size=self.sequence_length)  # Gravity\n",
    "                \n",
    "                gyro_x = 0.1 * np.sin(2 * np.pi * 2 * time_steps) + 0.02 * np.random.normal(size=self.sequence_length)\n",
    "                gyro_y = 0.1 * np.cos(2 * np.pi * 2 * time_steps) + 0.02 * np.random.normal(size=self.sequence_length)\n",
    "                gyro_z = 0.01 * np.random.normal(size=self.sequence_length)\n",
    "                \n",
    "                stress = np.random.uniform(0.0, 0.4)\n",
    "                fatigue = np.random.uniform(0.0, 0.3)\n",
    "                anomaly = 0.0\n",
    "                \n",
    "            elif i < num_samples * 0.85:  # 15% stressed movement\n",
    "                # Jerky, tense movements with tremors\n",
    "                tremor_freq = 8  # 8Hz tremor\n",
    "                tremor = 0.2 * np.sin(2 * np.pi * tremor_freq * time_steps)\n",
    "                \n",
    "                accel_x = 0.7 * np.sin(2 * np.pi * 1 * time_steps) + tremor + 0.2 * np.random.normal(size=self.sequence_length)\n",
    "                accel_y = 0.7 * np.cos(2 * np.pi * 1 * time_steps) + tremor + 0.2 * np.random.normal(size=self.sequence_length)\n",
    "                accel_z = 9.8 + 0.1 * np.random.normal(size=self.sequence_length)\n",
    "                \n",
    "                gyro_x = 0.2 * np.sin(2 * np.pi * 2 * time_steps) + 0.1 * tremor + 0.05 * np.random.normal(size=self.sequence_length)\n",
    "                gyro_y = 0.2 * np.cos(2 * np.pi * 2 * time_steps) + 0.1 * tremor + 0.05 * np.random.normal(size=self.sequence_length)\n",
    "                gyro_z = 0.05 * np.random.normal(size=self.sequence_length)\n",
    "                \n",
    "                stress = np.random.uniform(0.6, 1.0)\n",
    "                fatigue = np.random.uniform(0.2, 0.6)\n",
    "                anomaly = 0.0\n",
    "                \n",
    "            else:  # 15% fatigued movement\n",
    "                # Slow, uncoordinated movements\n",
    "                accel_x = 0.3 * np.sin(2 * np.pi * 0.5 * time_steps) + 0.15 * np.random.normal(size=self.sequence_length)\n",
    "                accel_y = 0.3 * np.cos(2 * np.pi * 0.5 * time_steps) + 0.15 * np.random.normal(size=self.sequence_length)\n",
    "                accel_z = 9.8 + 0.2 * np.random.normal(size=self.sequence_length)\n",
    "                \n",
    "                gyro_x = 0.05 * np.sin(2 * np.pi * 1 * time_steps) + 0.08 * np.random.normal(size=self.sequence_length)\n",
    "                gyro_y = 0.05 * np.cos(2 * np.pi * 1 * time_steps) + 0.08 * np.random.normal(size=self.sequence_length)\n",
    "                gyro_z = 0.08 * np.random.normal(size=self.sequence_length)\n",
    "                \n",
    "                stress = np.random.uniform(0.2, 0.5)\n",
    "                fatigue = np.random.uniform(0.7, 1.0)\n",
    "                anomaly = 0.0\n",
    "            \n",
    "            # Add occasional anomalies (1%)\n",
    "            if np.random.random() < 0.01:\n",
    "                anomaly = 1.0\n",
    "                # Add abnormal patterns\n",
    "                accel_x += 2.0 * np.random.normal(size=self.sequence_length)\n",
    "                accel_y += 2.0 * np.random.normal(size=self.sequence_length)\n",
    "            \n",
    "            # Combine features\n",
    "            features = np.column_stack([\n",
    "                accel_x, accel_y, accel_z,\n",
    "                gyro_x, gyro_y, gyro_z,\n",
    "                np.gradient(accel_x),  # Jerk features\n",
    "                np.gradient(accel_y),\n",
    "                np.convolve(accel_x, np.ones(5)/5, mode='same'),  # Smoothed\n",
    "                np.convolve(accel_y, np.ones(5)/5, mode='same'),\n",
    "                np.sqrt(accel_x**2 + accel_y**2 + accel_z**2),  # Magnitude\n",
    "                np.sqrt(gyro_x**2 + gyro_y**2 + gyro_z**2)\n",
    "            ])\n",
    "            \n",
    "            X.append(features)\n",
    "            stress_labels.append(stress)\n",
    "            fatigue_labels.append(fatigue)\n",
    "            anomaly_labels.append(anomaly)\n",
    "        \n",
    "        X = np.array(X)\n",
    "        labels = {\n",
    "            'stress': np.array(stress_labels),\n",
    "            'fatigue': np.array(fatigue_labels),\n",
    "            'anomaly': np.array(anomaly_labels)\n",
    "        }\n",
    "        \n",
    "        self.logger.info(f\"âœ… Generated {num_samples} movement samples\")\n",
    "        return X, labels\n",
    "    \n",
    "    def build_movement_model(self):\n",
    "        \"\"\"Build LSTM-based movement analysis model\"\"\"\n",
    "        inputs = tf.keras.Input(shape=(self.sequence_length, self.feature_dim))\n",
    "        \n",
    "        # Bidirectional LSTM for temporal patterns\n",
    "       \n",
    "        x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, implementation=2))(inputs)\n",
    "\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        \n",
    "        x = layers.Bidirectional(layers.LSTM(32, return_sequences=False, implementation=2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        # (For simplicity, using dense layers instead of proper attention for sequences)\n",
    "        attention_weights = layers.Dense(64, activation='tanh')(x)\n",
    "        attention_weights = layers.Dense(1, activation='sigmoid')(attention_weights)\n",
    "        \n",
    "        # Apply attention (simplified)\n",
    "        attended = layers.multiply([x, attention_weights])\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = layers.Dense(128, activation='relu')(attended)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        \n",
    "        # Multi-output\n",
    "        stress_output = layers.Dense(1, activation='sigmoid', name='stress')(x)\n",
    "        fatigue_output = layers.Dense(1, activation='sigmoid', name='fatigue')(x)\n",
    "        anomaly_output = layers.Dense(1, activation='sigmoid', name='anomaly')(x)\n",
    "        \n",
    "        self.model = models.Model(inputs=inputs, outputs=[stress_output, fatigue_output, anomaly_output])\n",
    "        return self.model\n",
    "    \n",
    "    def train_model(self, epochs=20, batch_size=128):\n",
    "        \"\"\"Train movement model on Kaggle GPU\"\"\"\n",
    "        self.logger.info(\"ðŸ‹ï¸ Training movement analysis model...\")\n",
    "        \n",
    "        # Generate data\n",
    "        X, labels = self.generate_realistic_movement_data(15000)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "        y_train = {k: v[:len(X_train)] for k, v in labels.items()}\n",
    "        y_test = {k: v[len(X_train):] for k, v in labels.items()}\n",
    "        \n",
    "        # Build model\n",
    "        self.build_movement_model()\n",
    "        \n",
    "        # Compile\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "            loss={\n",
    "                'stress': 'binary_crossentropy',\n",
    "                'fatigue': 'binary_crossentropy', \n",
    "                'anomaly': 'binary_crossentropy'\n",
    "            },\n",
    "            metrics=['accuracy', 'precision', 'recall']\n",
    "        )\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks_list = [\n",
    "            callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=8,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-7\n",
    "            ),\n",
    "            callbacks.ModelCheckpoint(\n",
    "                '/kaggle/working/movement_analyzer_best.h5',\n",
    "                monitor='val_stress_loss',\n",
    "                save_best_only=True\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Train\n",
    "        self.logger.info(\"Starting training...\")\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks_list,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Save final model\n",
    "        self.model.save('/kaggle/working/movement_analyzer.h5')\n",
    "        \n",
    "        # Save history\n",
    "        with open('/kaggle/working/movement_training_history.json', 'w') as f:\n",
    "            json.dump({k: [float(x) for x in v] for k, v in history.history.items()}, f)\n",
    "        \n",
    "        self.logger.info(\"âœ… Movement model training complete!\")\n",
    "        return history\n",
    "    \n",
    "    def convert_to_tflite(self):\n",
    "        \"\"\"Convert to TFLite format\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Train the model first!\")\n",
    "        \n",
    "        self.logger.info(\"ðŸ”„ Converting movement model to TFLite...\")\n",
    "        \n",
    "        # Load some data for representative dataset\n",
    "        X, _ = self.generate_realistic_movement_data(100)\n",
    "        \n",
    "        def representative_gen():\n",
    "            for i in range(50):\n",
    "                yield [X[i:i+1].astype(np.float32)]\n",
    "        \n",
    "        # Convert\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(self.model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = representative_gen\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "        converter.inference_input_type = tf.int8\n",
    "        converter.inference_output_type = tf.int8\n",
    "        \n",
    "        tflite_model = converter.convert()\n",
    "        \n",
    "        with open('/kaggle/working/movement_analyzer_int8.tflite', 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        \n",
    "        self.logger.info(\"âœ… Movement TFLite model saved!\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for movement model training\"\"\"\n",
    "    print(\"ðŸš€ Starting Movement Model Training on Kaggle\")\n",
    "    \n",
    "    # Initialize and train\n",
    "    trainer = MovementModelTrainerKaggle(sequence_length=50, feature_dim=12)\n",
    "    \n",
    "    try:\n",
    "        # Train model\n",
    "        history = trainer.train_model(epochs=20, batch_size=128)\n",
    "        \n",
    "        # Convert to TFLite\n",
    "        trainer.convert_to_tflite()\n",
    "        \n",
    "        print(\"\\nðŸŽ‰ Movement model training completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Movement model training failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96facb18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T08:45:04.695069Z",
     "iopub.status.busy": "2025-11-26T08:45:04.694882Z",
     "iopub.status.idle": "2025-11-26T08:45:04.702849Z",
     "shell.execute_reply": "2025-11-26T08:45:04.702284Z"
    },
    "papermill": {
     "duration": 0.014222,
     "end_time": "2025-11-26T08:45:04.703834",
     "exception": false,
     "start_time": "2025-11-26T08:45:04.689612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/src/train_fusion_model_kaggle.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/src/train_fusion_model_kaggle.py \n",
    "# train_fusion_model_kaggle.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"âœ… Fusion model Kaggle script loaded\")\n",
    "\n",
    "class FusionModelTrainerKaggle:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.setup_logging()\n",
    "    \n",
    "    def setup_logging(self):\n",
    "        \"\"\"Setup logging for Kaggle\"\"\"\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger('FusionModelTrainer')\n",
    "    \n",
    "    def generate_fusion_data(self, num_samples=10000):\n",
    "        \"\"\"Generate realistic fusion data combining face, movement, and HR features\"\"\"\n",
    "        self.logger.info(\"ðŸ“Š Generating fusion training data...\")\n",
    "        \n",
    "        # Simulate outputs from individual models\n",
    "        face_features = np.random.normal(0, 1, (num_samples, 32)).astype(np.float32)\n",
    "        movement_features = np.random.normal(0, 1, (num_samples, 24)).astype(np.float32)\n",
    "        hr_features = np.random.normal(0, 1, (num_samples, 3)).astype(np.float32)\n",
    "        \n",
    "        # Generate realistic final labels based on combined features\n",
    "        stress_labels = []\n",
    "        fatigue_labels = []\n",
    "        anomaly_labels = []\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            # Combine information from all sensors\n",
    "            face_stress_indicator = np.mean(face_features[i, :8])  # First 8 face features\n",
    "            movement_stress_indicator = np.mean(movement_features[i, 6:12])  # Movement stress features\n",
    "            hr_stress_indicator = hr_features[i, 2]  # HR variability\n",
    "            \n",
    "            # Final stress score (weighted combination)\n",
    "            stress_score = (\n",
    "                0.4 * self._sigmoid(face_stress_indicator) +\n",
    "                0.4 * self._sigmoid(movement_stress_indicator) + \n",
    "                0.2 * hr_stress_indicator +\n",
    "                np.random.normal(0, 0.1)\n",
    "            )\n",
    "            stress_labels.append(np.clip(stress_score, 0, 1))\n",
    "            \n",
    "            # Fatigue calculation\n",
    "            face_fatigue_indicator = np.mean(face_features[i, 8:16])  # Face fatigue features\n",
    "            movement_fatigue_indicator = np.mean(movement_features[i, :6])  # Movement smoothness\n",
    "            \n",
    "            fatigue_score = (\n",
    "                0.5 * self._sigmoid(face_fatigue_indicator) +\n",
    "                0.5 * self._sigmoid(movement_fatigue_indicator) +\n",
    "                np.random.normal(0, 0.1)\n",
    "            )\n",
    "            fatigue_labels.append(np.clip(fatigue_score, 0, 1))\n",
    "            \n",
    "            # Anomaly detection (based on feature inconsistencies)\n",
    "            feature_consistency = np.std([face_stress_indicator, movement_stress_indicator, hr_stress_indicator])\n",
    "            anomaly_score = min(1.0, feature_consistency * 2.0)\n",
    "            \n",
    "            # Add rare true anomalies\n",
    "            if np.random.random() < 0.02:  # 2% true anomalies\n",
    "                anomaly_labels.append(1.0)\n",
    "            else:\n",
    "                anomaly_labels.append(1.0 if anomaly_score > 0.8 and np.random.random() < 0.3 else 0.0)\n",
    "        \n",
    "        inputs = {\n",
    "            'face_features': face_features,\n",
    "            'movement_features': movement_features,\n",
    "            'hr_features': hr_features\n",
    "        }\n",
    "        \n",
    "        labels = {\n",
    "            'stress': np.array(stress_labels),\n",
    "            'fatigue': np.array(fatigue_labels),\n",
    "            'anomaly': np.array(anomaly_labels)\n",
    "        }\n",
    "        \n",
    "        self.logger.info(f\"âœ… Generated {num_samples} fusion samples\")\n",
    "        return inputs, labels\n",
    "    \n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"Helper sigmoid function\"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def build_fusion_model(self):\n",
    "        \"\"\"Build sensor fusion model with attention mechanism\"\"\"\n",
    "        # Inputs from different sensors\n",
    "        face_input = tf.keras.Input(shape=(32,), name='face_features')\n",
    "        movement_input = tf.keras.Input(shape=(24,), name='movement_features')\n",
    "        hr_input = tf.keras.Input(shape=(3,), name='hr_features')\n",
    "        \n",
    "        # Feature transformation with batch normalization\n",
    "        face_branch = layers.Dense(64, activation='relu')(face_input)\n",
    "        face_branch = layers.BatchNormalization()(face_branch)\n",
    "        face_branch = layers.Dropout(0.2)(face_branch)\n",
    "        \n",
    "        movement_branch = layers.Dense(64, activation='relu')(movement_input)\n",
    "        movement_branch = layers.BatchNormalization()(movement_branch)\n",
    "        movement_branch = layers.Dropout(0.2)(movement_branch)\n",
    "        \n",
    "        hr_branch = layers.Dense(16, activation='relu')(hr_input)\n",
    "        hr_branch = layers.BatchNormalization()(hr_branch)\n",
    "        hr_branch = layers.Dropout(0.2)(hr_branch)\n",
    "        \n",
    "        # Concatenate all features\n",
    "        concatenated = layers.concatenate([face_branch, movement_branch, hr_branch])\n",
    "        \n",
    "        # Attention mechanism for feature weighting\n",
    "        attention = layers.Dense(concatenated.shape[-1], activation='tanh')(concatenated)\n",
    "        attention = layers.Dense(concatenated.shape[-1], activation='softmax')(attention)\n",
    "        \n",
    "        # Apply attention\n",
    "        attended_features = layers.multiply([concatenated, attention])\n",
    "        \n",
    "        # Main fusion network\n",
    "        x = layers.Dense(128, activation='relu')(attended_features)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        \n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        x = layers.Dense(32, activation='relu')(x)\n",
    "        \n",
    "        # Multi-output for final health assessment\n",
    "        stress_output = layers.Dense(1, activation='sigmoid', name='stress')(x)\n",
    "        fatigue_output = layers.Dense(1, activation='sigmoid', name='fatigue')(x)\n",
    "        anomaly_output = layers.Dense(1, activation='sigmoid', name='anomaly')(x)\n",
    "        \n",
    "        self.model = models.Model(\n",
    "            inputs=[face_input, movement_input, hr_input],\n",
    "            outputs=[stress_output, fatigue_output, anomaly_output]\n",
    "        )\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def train_model(self, epochs=15, batch_size=64):\n",
    "        \"\"\"Train fusion model on Kaggle GPU\"\"\"\n",
    "        self.logger.info(\"ðŸ‹ï¸ Training sensor fusion model...\")\n",
    "        \n",
    "        # Generate data\n",
    "        inputs, labels = self.generate_fusion_data(10000)\n",
    "        \n",
    "        # Build model\n",
    "        self.build_fusion_model()\n",
    "        \n",
    "        # Compile\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "            loss={\n",
    "                'stress': 'binary_crossentropy',\n",
    "                'fatigue': 'binary_crossentropy',\n",
    "                'anomaly': 'binary_crossentropy'\n",
    "            },\n",
    "            metrics=['accuracy', 'precision', 'recall']\n",
    "        )\n",
    "        \n",
    "        # Split data\n",
    "        train_idx, test_idx = train_test_split(range(len(inputs['face_features'])), test_size=0.2, random_state=42)\n",
    "        \n",
    "        X_train = {k: v[train_idx] for k, v in inputs.items()}\n",
    "        X_test = {k: v[test_idx] for k, v in inputs.items()}\n",
    "        y_train = {k: v[train_idx] for k, v in labels.items()}\n",
    "        y_test = {k: v[test_idx] for k, v in labels.items()}\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks_list = [\n",
    "            callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=8,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=4,\n",
    "                min_lr=1e-7\n",
    "            ),\n",
    "            callbacks.ModelCheckpoint(\n",
    "                '/kaggle/working/fusion_engine_best.h5',\n",
    "                monitor='val_stress_loss',\n",
    "                save_best_only=True\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Train\n",
    "        self.logger.info(\"Starting training...\")\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks_list,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Save final model\n",
    "        self.model.save('/kaggle/working/fusion_engine.h5')\n",
    "        \n",
    "        # Save history\n",
    "        with open('/kaggle/working/fusion_training_history.json', 'w') as f:\n",
    "            json.dump({k: [float(x) for x in v] for k, v in history.history.items()}, f)\n",
    "        \n",
    "        self.logger.info(\"âœ… Fusion model training complete!\")\n",
    "        return history\n",
    "    \n",
    "    def convert_to_tflite(self):\n",
    "        \"\"\"Convert to TFLite format\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Train the model first!\")\n",
    "        \n",
    "        self.logger.info(\"ðŸ”„ Converting fusion model to TFLite...\")\n",
    "        \n",
    "        # Generate representative data\n",
    "        inputs, _ = self.generate_fusion_data(100)\n",
    "        \n",
    "        def representative_gen():\n",
    "            for i in range(50):\n",
    "                yield {\n",
    "                    'face_features': inputs['face_features'][i:i+1].astype(np.float32),\n",
    "                    'movement_features': inputs['movement_features'][i:i+1].astype(np.float32),\n",
    "                    'hr_features': inputs['hr_features'][i:i+1].astype(np.float32)\n",
    "                }\n",
    "        \n",
    "        # Convert\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(self.model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = representative_gen\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "        converter.inference_input_type = tf.int8\n",
    "        converter.inference_output_type = tf.int8\n",
    "        \n",
    "        tflite_model = converter.convert()\n",
    "        \n",
    "        with open('/kaggle/working/fusion_engine_int8.tflite', 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        \n",
    "        self.logger.info(\"âœ… Fusion TFLite model saved!\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for fusion model training\"\"\"\n",
    "    print(\"ðŸš€ Starting Fusion Model Training on Kaggle\")\n",
    "    \n",
    "    # Initialize and train\n",
    "    trainer = FusionModelTrainerKaggle()\n",
    "    \n",
    "    try:\n",
    "        # Train model\n",
    "        history = trainer.train_model(epochs=15, batch_size=64)\n",
    "        \n",
    "        # Convert to TFLite\n",
    "        trainer.convert_to_tflite()\n",
    "        \n",
    "        print(\"\\nðŸŽ‰ Fusion model training completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fusion model training failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d085b4a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T08:45:04.713310Z",
     "iopub.status.busy": "2025-11-26T08:45:04.713066Z",
     "iopub.status.idle": "2025-11-26T08:45:08.737260Z",
     "shell.execute_reply": "2025-11-26T08:45:08.736280Z"
    },
    "papermill": {
     "duration": 4.030437,
     "end_time": "2025-11-26T08:45:08.738649",
     "exception": false,
     "start_time": "2025-11-26T08:45:04.708212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Setting up Edge Health Guardian Training on Kaggle\n",
      "Collecting tensorflow-model-optimization\r\n",
      "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\r\n",
      "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.4.0)\r\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (0.1.9)\r\n",
      "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.26.4)\r\n",
      "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.17.0)\r\n",
      "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (25.4.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (1.17.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (2.4.1)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy~=1.23->tensorflow-model-optimization) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy~=1.23->tensorflow-model-optimization) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy~=1.23->tensorflow-model-optimization) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy~=1.23->tensorflow-model-optimization) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy~=1.23->tensorflow-model-optimization) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy~=1.23->tensorflow-model-optimization) (2024.2.0)\r\n",
      "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tensorflow-model-optimization\r\n",
      "Successfully installed tensorflow-model-optimization-0.8.0\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"ðŸš€ Setting up Edge Health Guardian Training on Kaggle\")\n",
    "!pip install tensorflow-model-optimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51f021b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T08:45:08.749776Z",
     "iopub.status.busy": "2025-11-26T08:45:08.749504Z",
     "iopub.status.idle": "2025-11-26T08:45:08.754975Z",
     "shell.execute_reply": "2025-11-26T08:45:08.754258Z"
    },
    "papermill": {
     "duration": 0.012528,
     "end_time": "2025-11-26T08:45:08.756220",
     "exception": false,
     "start_time": "2025-11-26T08:45:08.743692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Movement model fix confirmed!\n"
     ]
    }
   ],
   "source": [
    "# Verify the fix is there\n",
    "with open('/kaggle/working/src/train_movement_model_kaggle.py', 'r') as f:\n",
    "    content = f.read()\n",
    "    if 'implementation=2' in content:\n",
    "        print(\"âœ… Movement model fix confirmed!\")\n",
    "    else:\n",
    "        print(\"âŒ Movement model fix missing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dac5fd56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T08:45:08.767188Z",
     "iopub.status.busy": "2025-11-26T08:45:08.766940Z",
     "iopub.status.idle": "2025-11-26T08:45:08.772384Z",
     "shell.execute_reply": "2025-11-26T08:45:08.771626Z"
    },
    "papermill": {
     "duration": 0.012422,
     "end_time": "2025-11-26T08:45:08.773527",
     "exception": false,
     "start_time": "2025-11-26T08:45:08.761105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/src/train_all_models_kaggle.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/src/train_all_models_kaggle.py\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ðŸš€ Training ALL Edge Health Guardian Models on Kaggle\")\n",
    "\n",
    "# Add to path\n",
    "sys.path.append('/kaggle/working/src')\n",
    "\n",
    "# Import training scripts\n",
    "from train_face_model_kaggle import FaceModelTrainerKaggle\n",
    "from train_movement_model_kaggle import MovementModelTrainerKaggle\n",
    "from train_fusion_model_kaggle import FusionModelTrainerKaggle\n",
    "\n",
    "def train_all_models():\n",
    "    \"\"\"Train all three models sequentially\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"ðŸŽ¯ Starting Complete Model Training\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Train Face Model\n",
    "    print(\"\\n1ï¸âƒ£  Training Face Analysis Model...\")\n",
    "    face_trainer = FaceModelTrainerKaggle()\n",
    "    face_trainer.train_model(epochs=30, batch_size=64)\n",
    "    face_trainer.convert_to_tflite()\n",
    "    \n",
    "    # 2. Train Movement Model  \n",
    "    print(\"\\n2ï¸âƒ£  Training Movement Analysis Model...\")\n",
    "    movement_trainer = MovementModelTrainerKaggle()\n",
    "    movement_trainer.train_model(epochs=20, batch_size=128)\n",
    "    movement_trainer.convert_to_tflite()\n",
    "    \n",
    "    # 3. Train Fusion Model\n",
    "    print(\"\\n3ï¸âƒ£  Training Sensor Fusion Model...\")\n",
    "    fusion_trainer = FusionModelTrainerKaggle()\n",
    "    fusion_trainer.train_model(epochs=15, batch_size=64)\n",
    "    fusion_trainer.convert_to_tflite()\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ ALL MODELS TRAINED SUCCESSFULLY!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "910bf9a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T08:45:08.784122Z",
     "iopub.status.busy": "2025-11-26T08:45:08.783896Z",
     "iopub.status.idle": "2025-11-26T08:45:09.080118Z",
     "shell.execute_reply": "2025-11-26T08:45:09.079198Z"
    },
    "papermill": {
     "duration": 0.302763,
     "end_time": "2025-11-26T08:45:09.081221",
     "exception": true,
     "start_time": "2025-11-26T08:45:08.778458",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'train_face_model_kaggle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21/2880659656.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain_face_model_kaggle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'train_face_model_kaggle'"
     ]
    }
   ],
   "source": [
    "from train_face_model_kaggle import *\n",
    "print(dir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8116bd0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# src/train_all_models_kaggle.py\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "print(\"ðŸš€ Training ALL Edge Health Guardian Models on Kaggle\")\n",
    "\n",
    "# Add to path\n",
    "sys.path.append('/kaggle/working/src')\n",
    "\n",
    "# Import training scripts\n",
    "from train_face_model_kaggle import FaceModelTrainerKaggle\n",
    "from train_movement_model_kaggle import MovementModelTrainerKaggle\n",
    "from train_fusion_model_kaggle import FusionModelTrainerKaggle\n",
    "\n",
    "def calculate_class_weights_for_face_model(y_train):\n",
    "    \"\"\"Calculate class weights for face model tasks\"\"\"\n",
    "    class_weights = {}\n",
    "    \n",
    "    for task in ['stress', 'fatigue', 'anomaly']:\n",
    "        if task in y_train:\n",
    "            # Convert to binary labels for weight calculation\n",
    "            binary_labels = (y_train[task] > 0.5).astype(int)\n",
    "            \n",
    "            try:\n",
    "                weights = compute_class_weight(\n",
    "                    'balanced', \n",
    "                    classes=np.unique(binary_labels), \n",
    "                    y=binary_labels\n",
    "                )\n",
    "                class_weights[task] = {0: float(weights[0]), 1: float(weights[1])}\n",
    "                print(f\"âœ… {task} class weights: {class_weights[task]}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Using default weights for {task}: {e}\")\n",
    "                class_weights[task] = {0: 1.0, 1: 1.0}\n",
    "    \n",
    "    return class_weights\n",
    "\n",
    "def train_all_models():\n",
    "    \"\"\"Train all three models sequentially with improved settings\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"ðŸŽ¯ Starting Complete Model Training\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Train Face Model\n",
    "    print(\"\\n1ï¸âƒ£  Training Face Analysis Model...\")\n",
    "    face_trainer = FaceModelTrainerKaggle()\n",
    "    \n",
    "    # Load data first to calculate class weights\n",
    "    print(\"ðŸ“¥ Loading face data for class weight calculation...\")\n",
    "    from train_face_model_kaggle import load_fer2013_with_health_labels\n",
    "    X_face, y_face = load_fer2013_with_health_labels()\n",
    "    \n",
    "    # Split data\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    indices = np.arange(len(X_face))\n",
    "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_train = X_face[train_idx]\n",
    "    X_val = X_face[val_idx]\n",
    "    y_train = {k: v[train_idx] for k, v in y_face.items()}\n",
    "    y_val = {k: v[val_idx] for k, v in y_face.items()}\n",
    "    \n",
    "    # Calculate class weights\n",
    "    class_weights = calculate_class_weights_for_face_model(y_train)\n",
    "    \n",
    "    # Train with class weights\n",
    "    face_trainer.train_model_with_data(\n",
    "        X_train=X_train, y_train=y_train, \n",
    "        X_val=X_val, y_val=y_val,\n",
    "        class_weights=class_weights,\n",
    "        epochs=30, \n",
    "        batch_size=64\n",
    "    )\n",
    "    face_trainer.convert_to_tflite()\n",
    "    \n",
    "    # 2. Train Movement Model  \n",
    "    print(\"\\n2ï¸âƒ£  Training Movement Analysis Model...\")\n",
    "    movement_trainer = MovementModelTrainerKaggle()\n",
    "    movement_trainer.train_model(epochs=20, batch_size=128)\n",
    "    movement_trainer.convert_to_tflite()\n",
    "    \n",
    "    # 3. Train Fusion Model\n",
    "    print(\"\\n3ï¸âƒ£  Training Sensor Fusion Model...\")\n",
    "    fusion_trainer = FusionModelTrainerKaggle()\n",
    "    fusion_trainer.train_model(epochs=15, batch_size=64)\n",
    "    fusion_trainer.convert_to_tflite()\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ ALL MODELS TRAINED SUCCESSFULLY!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd113d52",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# src/train_movement_model_kaggle.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"âœ… Movement model script loaded\")\n",
    "\n",
    "class MovementModelTrainerKaggle:\n",
    "    def __init__(self, sequence_length=50, feature_dim=12):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.feature_dim = feature_dim\n",
    "        self.model = None\n",
    "        self.setup_logging()\n",
    "    \n",
    "    def setup_logging(self):\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger('MovementModelTrainer')\n",
    "    \n",
    "    def generate_synthetic_movement_data(self, num_samples=10000):\n",
    "        \"\"\"Generate synthetic movement data\"\"\"\n",
    "        self.logger.info(\"ðŸ“Š Generating movement data...\")\n",
    "        \n",
    "        # Simulate accelerometer and gyroscope data\n",
    "        X = np.random.randn(num_samples, self.sequence_length, self.feature_dim).astype(np.float32)\n",
    "        \n",
    "        # Generate labels\n",
    "        stress_labels = np.random.uniform(0, 1, num_samples)\n",
    "        fatigue_labels = np.random.uniform(0, 1, num_samples) \n",
    "        anomaly_labels = (np.random.random(num_samples) > 0.95).astype(float)\n",
    "        \n",
    "        labels = {\n",
    "            'stress': stress_labels,\n",
    "            'fatigue': fatigue_labels,\n",
    "            'anomaly': anomaly_labels\n",
    "        }\n",
    "        \n",
    "        return X, labels\n",
    "    \n",
    "    def train_model(self, epochs=20, batch_size=128):\n",
    "        \"\"\"Train movement model on Kaggle\"\"\"\n",
    "        self.logger.info(\"ðŸ‹ï¸ Training movement model...\")\n",
    "        \n",
    "        # Generate data\n",
    "        X, labels = self.generate_synthetic_movement_data()\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "        y_train = {k: v[:len(X_train)] for k, v in labels.items()}\n",
    "        y_test = {k: v[len(X_train):] for k, v in labels.items()}\n",
    "        \n",
    "        # Build simple LSTM model (you can replace with your actual architecture)\n",
    "        from tensorflow.keras import layers, models\n",
    "        \n",
    "        inputs = tf.keras.Input(shape=(self.sequence_length, self.feature_dim))\n",
    "        x = layers.LSTM(64, return_sequences=True)(inputs)\n",
    "        x = layers.LSTM(32)(x)\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        \n",
    "        stress_output = layers.Dense(1, activation='sigmoid', name='stress')(x)\n",
    "        fatigue_output = layers.Dense(1, activation='sigmoid', name='fatigue')(x)\n",
    "        anomaly_output = layers.Dense(1, activation='sigmoid', name='anomaly')(x)\n",
    "        \n",
    "        self.model = models.Model(inputs=inputs, outputs=[stress_output, fatigue_output, anomaly_output])\n",
    "        \n",
    "        # Compile\n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss={'stress': 'mse', 'fatigue': 'mse', 'anomaly': 'binary_crossentropy'},\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Save\n",
    "        self.model.save('/kaggle/working/movement_analyzer.h5')\n",
    "        self.logger.info(\"âœ… Movement model saved!\")\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def convert_to_tflite(self):\n",
    "        \"\"\"Convert to TFLite\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Train model first!\")\n",
    "        \n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(self.model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite_model = converter.convert()\n",
    "        \n",
    "        with open('/kaggle/working/movement_analyzer_int8.tflite', 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        \n",
    "        self.logger.info(\"âœ… Movement TFLite model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878b799",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# src/train_fusion_model_kaggle.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "\n",
    "print(\"âœ… Fusion model script loaded\")\n",
    "\n",
    "class FusionModelTrainerKaggle:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.setup_logging()\n",
    "    \n",
    "    def setup_logging(self):\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger('FusionModelTrainer')\n",
    "    \n",
    "    def generate_fusion_data(self, num_samples=5000):\n",
    "        \"\"\"Generate synthetic fusion data\"\"\"\n",
    "        self.logger.info(\"ðŸ“Š Generating fusion data...\")\n",
    "        \n",
    "        # Simulate outputs from face and movement models\n",
    "        face_features = np.random.randn(num_samples, 32).astype(np.float32)\n",
    "        movement_features = np.random.randn(num_samples, 24).astype(np.float32)\n",
    "        hr_features = np.random.randn(num_samples, 3).astype(np.float32)\n",
    "        \n",
    "        # Generate final labels\n",
    "        stress_labels = np.random.uniform(0, 1, num_samples)\n",
    "        fatigue_labels = np.random.uniform(0, 1, num_samples)\n",
    "        anomaly_labels = (np.random.random(num_samples) > 0.98).astype(float)\n",
    "        \n",
    "        inputs = {\n",
    "            'face': face_features,\n",
    "            'movement': movement_features, \n",
    "            'hr': hr_features\n",
    "        }\n",
    "        \n",
    "        labels = {\n",
    "            'stress': stress_labels,\n",
    "            'fatigue': fatigue_labels,\n",
    "            'anomaly': anomaly_labels\n",
    "        }\n",
    "        \n",
    "        return inputs, labels\n",
    "    \n",
    "    def train_model(self, epochs=15, batch_size=64):\n",
    "        \"\"\"Train fusion model\"\"\"\n",
    "        self.logger.info(\"ðŸ‹ï¸ Training fusion model...\")\n",
    "        \n",
    "        # Generate data\n",
    "        inputs, labels = self.generate_fusion_data()\n",
    "        \n",
    "        # Build fusion model\n",
    "        from tensorflow.keras import layers, models\n",
    "        \n",
    "        face_input = tf.keras.Input(shape=(32,), name='face_features')\n",
    "        movement_input = tf.keras.Input(shape=(24,), name='movement_features') \n",
    "        hr_input = tf.keras.Input(shape=(3,), name='hr_features')\n",
    "        \n",
    "        # Process each input\n",
    "        face_branch = layers.Dense(64, activation='relu')(face_input)\n",
    "        movement_branch = layers.Dense(64, activation='relu')(movement_input)\n",
    "        hr_branch = layers.Dense(16, activation='relu')(hr_input)\n",
    "        \n",
    "        # Concatenate\n",
    "        concatenated = layers.concatenate([face_branch, movement_branch, hr_branch])\n",
    "        \n",
    "        # Final layers\n",
    "        x = layers.Dense(128, activation='relu')(concatenated)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        \n",
    "        # Outputs\n",
    "        stress_output = layers.Dense(1, activation='sigmoid', name='stress')(x)\n",
    "        fatigue_output = layers.Dense(1, activation='sigmoid', name='fatigue')(x)\n",
    "        anomaly_output = layers.Dense(1, activation='sigmoid', name='anomaly')(x)\n",
    "        \n",
    "        self.model = models.Model(\n",
    "            inputs=[face_input, movement_input, hr_input],\n",
    "            outputs=[stress_output, fatigue_output, anomaly_output]\n",
    "        )\n",
    "        \n",
    "        # Compile\n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss={'stress': 'mse', 'fatigue': 'mse', 'anomaly': 'binary_crossentropy'},\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        # Split data\n",
    "        train_idx, test_idx = train_test_split(range(len(inputs['face'])), test_size=0.2)\n",
    "        \n",
    "        X_train = {k: v[train_idx] for k, v in inputs.items()}\n",
    "        X_test = {k: v[test_idx] for k, v in inputs.items()}\n",
    "        y_train = {k: v[train_idx] for k, v in labels.items()}\n",
    "        y_test = {k: v[test_idx] for k, v in labels.items()}\n",
    "        \n",
    "        # Train\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Save\n",
    "        self.model.save('/kaggle/working/fusion_engine.h5')\n",
    "        self.logger.info(\"âœ… Fusion model saved!\")\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def convert_to_tflite(self):\n",
    "        \"\"\"Convert to TFLite\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Train model first!\")\n",
    "        \n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(self.model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite_model = converter.convert()\n",
    "        \n",
    "        with open('/kaggle/working/fusion_engine_int8.tflite', 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        \n",
    "        self.logger.info(\"âœ… Fusion TFLite model saved!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 28577,
     "isSourceIdPinned": false,
     "sourceId": 36420,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 83.945114,
   "end_time": "2025-11-26T08:45:12.324384",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-26T08:43:48.379270",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
